{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable GPU acceleration\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "BATCH = 1\n",
    "\n",
    "class VisOdoNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Convolutional layers to learn spatial features and adjust channels\n",
    "        self.conv1 = nn.Conv2d(4, 3, kernel_size=5, padding=2)\n",
    "\n",
    "        # Pretrained Resnet\n",
    "        self.r50 = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "\n",
    "        # LSTM network to learn temporal features\n",
    "        self.rnn1 = nn.LSTM(input_size=1000,\n",
    "                            hidden_size=8, num_layers=4,\n",
    "                            bidirectional=False, # should be monotonic\n",
    "                            batch_first=True)\n",
    "\n",
    "        # And a few FC layers to tie it all together\n",
    "        self.fc1 = nn.Linear(64, 16)\n",
    "        self.fc2 = nn.Linear(16, BATCH)\n",
    "\n",
    "    def forward(self, x):         # input [B x 59 x 4 x 256 x 256]\n",
    "        x = torch.squeeze(x)      # shape [59 x 4 x 256 x 256] --> \"Batch\" of 59\n",
    "        x = F.relu(self.conv1(x)) # shape [B x 3 x 256 x 256]\n",
    "\n",
    "        # Use ResNet50 to reduce dimensionality\n",
    "        x = self.r50(x)        # shape [B x 1000]\n",
    "\n",
    "        _, (x, c) = self.rnn1(x)  # pull both hidden and cell states\n",
    "        x = x.reshape(-1, 32) # B x 32 hidden state\n",
    "        c = c.reshape(-1, 32) # B x 32 cell state\n",
    "        x = torch.concat((x,c))\n",
    "        x = F.relu(x.reshape(-1, 64))   # [B x 64]\n",
    "        x = F.relu(self.fc1(x))   # shape [B x 16]\n",
    "        x = F.relu(self.fc2(x))   # shape [B]\n",
    "        return x.reshape(-1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class VideoSet(Dataset):\n",
    "    def __init__(self, tar_paths):\n",
    "        self.paths = tar_paths\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        tar = torch.load(self.paths[idx], weights_only = True)\n",
    "        videotensor = torch.stack(tar[\"frames\"], dim = 0)\n",
    "        labeltensor = tar[\"target\"][0]\n",
    "        \n",
    "               # Tensor[59x4x256x256], float32\n",
    "        return (videotensor, labeltensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import sample\n",
    "\n",
    "videos_path = \"/home/tjw/Downloads/VisOdo\"\n",
    "all_videos = os.listdir(videos_path)\n",
    "\n",
    "n_train = int(0.7*len(all_videos))\n",
    "n_test = int(0.3*len(all_videos))\n",
    "# n_test = len(all_videos) - n_train\n",
    "\n",
    "training_videos = sample(all_videos, k = n_train)\n",
    "# testing_videos = [os.path.join(videos_path, v) for v in all_videos if v not in training_videos]\n",
    "testing_videos = [os.path.join(videos_path, v) for v in sample(all_videos, k=n_test) if v not in training_videos]\n",
    "training_videos = [os.path.join(videos_path, v) for v in training_videos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_set = VideoSet(training_videos)\n",
    "test_set = VideoSet(testing_videos)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset = train_set,\n",
    "    shuffle = False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset = test_set,\n",
    "    shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from random import choice\n",
    "\n",
    "def train(epoch, model, device, optimizer, data_loader, loss_function):\n",
    "    # Prepare model\n",
    "    model = model.to(device)\n",
    "    model = model.train()\n",
    "    i = 0\n",
    "    GRAD_ACCUM = 10\n",
    "    predictions = []\n",
    "    correct = []\n",
    "    losses = []\n",
    "    \n",
    "    for batch_idx, (frame, y) in enumerate(data_loader):\n",
    "        frame = frame.to(device)\n",
    "        \n",
    "        # Quickly converges to loss=0, proves that training process works\n",
    "        # if choice([True, False]):\n",
    "        #     frame[:] = 0\n",
    "        #     y = torch.tensor(0)\n",
    "        # else:\n",
    "        #     frame[:] = 1\n",
    "        #     y = torch.tensor(1)\n",
    "        \n",
    "        y = y.to(device).type(torch.float)\n",
    "        correct.append(float(y))\n",
    "        \n",
    "        # Calculate and record output & loss\n",
    "        output = model(frame)\n",
    "        predictions.append(float(output.cpu()))\n",
    "        loss = loss_function(output, y)/GRAD_ACCUM\n",
    "        loss.backward()\n",
    "        losses.append(float(loss.cpu())*GRAD_ACCUM)\n",
    "        i += 1\n",
    "        \n",
    "        # Gradient accumulation & plotting\n",
    "        if i >= GRAD_ACCUM:\n",
    "            optimizer.step()\n",
    "            i = 0\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        # Periodically report on training progress\n",
    "        print(f\"\\rEpoch {epoch}: Training {batch_idx*BATCH}/{len(data_loader.dataset)} \" + \n",
    "              f\"(Loss: {loss.item():02.4})\", end=\" \"*10)\n",
    "    print(f\"\\rEpoch {epoch}: Trained {len(data_loader.dataset)}/{len(data_loader.dataset)} \" + \n",
    "              f\"(Loss: {loss.item():02.4})\" + \" \"*10)\n",
    "    \n",
    "    # Sort plotted values because otherwise they would be very noisy\n",
    "    pairs = sorted(zip(correct, predictions))\n",
    "    correct, predictions = zip(*pairs)\n",
    "    \n",
    "    # Plot to gauge accuracy of that epoch\n",
    "    plt.figure()\n",
    "    plt.plot(predictions, color=\"tab:blue\", label=\"Predicted\")\n",
    "    plt.plot(correct, color=\"tab:red\", label=\"Truth\")\n",
    "    plt.ylabel(\"Speed (m/s)\")\n",
    "    plt.tick_params(axis='x', which='both', bottom=False, labelbottom=False)\n",
    "    plt.title(f\"Epoch {epoch}\")\n",
    "    plt.legend()\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch, model, device, data_loader, loss_function):\n",
    "    model = model.to(device)\n",
    "    model = model.eval()\n",
    "    test_loss = []\n",
    "    map = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (frame, y) in enumerate(data_loader):\n",
    "            # Load data into `device`\n",
    "            frame = frame.to(device)\n",
    "            y = y.to(device).type(torch.float)\n",
    "            \n",
    "            # Calculate prediction & loss\n",
    "            output = model(frame)\n",
    "            test_loss.append(loss_function(output, y).item())\n",
    "            map.append(torch.mean(torch.abs((output - y) / y)) * 100)\n",
    "            \n",
    "            # Periodically report on testing progress\n",
    "            print(f\"\\rEpoch {epoch}: Testing {batch_idx*BATCH}/{len(data_loader.dataset)}, estimated MAPE {torch.mean(torch.tensor(map)):02.4}%\", end=\" \"*10)\n",
    "        print(f\"\\rEpoch {epoch}: Testing {len(data_loader.dataset)}/{len(data_loader.dataset)}\" + \" \"*30)\n",
    "    \n",
    "    # Report results\n",
    "    test_loss = torch.mean(torch.tensor(test_loss))\n",
    "    accuracy = torch.tensor(map)\n",
    "    print(f\"Test Result, epoch {epoch}: Avg loss {test_loss:04.4}, MAPE {torch.mean(accuracy):02.4}%\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models & parameters\n",
    "model = VisOdoNet()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), amsgrad=True, weight_decay=0.02)\n",
    "\n",
    "MAX_EPOCH = 50\n",
    "\n",
    "def h_loss(x, y):\n",
    "    return F.huber_loss(input=x, target=y, delta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test Loop!\n",
    "for epoch in range(1, 1+MAX_EPOCH):\n",
    "    train(epoch, model, device, optimizer, train_loader, F.huber_loss)\n",
    "    test(epoch, model, device, test_loader, F.mse_loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
